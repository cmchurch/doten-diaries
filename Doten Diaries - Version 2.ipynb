{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#CHRISTOPHER M. CHURCH\n",
    "#ASSISTANT PROFESSOR\n",
    "#UNIVERSITY OF NEVADA, RENO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#SPLIT THE PDF FROM 2-PAGE PER PAGE (COLUMNED) TO 1-PAGE PER PAGE (NO COLUMNS)\n",
    "#\n",
    "import copy\n",
    "import sys\n",
    "import math\n",
    "import pyPdf\n",
    "\n",
    "def split_pages(src, dst1,dst2):\n",
    "    '''splits a PDF from a 2-page multipage format into one-page-per-page format, using input and output\n",
    "       Source http://stackoverflow.com/a/15741856/1301753'''\n",
    "    src_f = file(src, 'r+b')\n",
    "    dst_f1 = file(dst1, 'w+b')\n",
    "    dst_f2 = file(dst2, 'w+b')\n",
    "\n",
    "    input = pyPdf.PdfFileReader(src_f)\n",
    "    output1 = pyPdf.PdfFileWriter()\n",
    "    output2 = pyPdf.PdfFileWriter()\n",
    "    \n",
    "    for i in range(input.getNumPages()):\n",
    "        p = input.getPage(i)\n",
    "        q = copy.copy(p)\n",
    "        q.mediaBox = copy.copy(p.mediaBox)\n",
    "\n",
    "        x1, x2 = p.mediaBox.lowerLeft\n",
    "        x3, x4 = p.mediaBox.upperRight\n",
    "\n",
    "        x1, x2 = math.floor(x1), math.floor(x2)\n",
    "        x3, x4 = math.floor(x3), math.floor(x4)\n",
    "        x5, x6 = math.floor(x3/2), math.floor(x4/2)\n",
    "\n",
    "        if x3 > x4:\n",
    "            # horizontal\n",
    "            p.mediaBox.upperRight = (x5, x4)\n",
    "            p.mediaBox.lowerLeft = (x1, x2)\n",
    "\n",
    "            q.mediaBox.upperRight = (x3, x4)\n",
    "            q.mediaBox.lowerLeft = (x5, x2)\n",
    "        else:\n",
    "            # vertical\n",
    "            p.mediaBox.upperRight = (x3, x4)\n",
    "            p.mediaBox.lowerLeft = (x1, x6)\n",
    "\n",
    "            q.mediaBox.upperRight = (x3, x6)\n",
    "            q.mediaBox.lowerLeft = (x1, x2)\n",
    "\n",
    "        output1.addPage(p)\n",
    "        output2.addPage(q)\n",
    "\n",
    "    output1.write(dst_f1)\n",
    "    output2.write(dst_f2)\n",
    "   \n",
    "    src_f.close()\n",
    "    dst_f1.close()\n",
    "    dst_f2.close()\n",
    "\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from cStringIO import StringIO\n",
    "\n",
    "def convert_pdf_to_txt(path):\n",
    "    '''this uses PDFMINER to extract the text contained within the PDF files'''\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)\n",
    "    fp = file(path, 'rb')\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    password = \"\"\n",
    "    maxpages = 0\n",
    "    caching = True\n",
    "    pagenos=set()\n",
    "\n",
    "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password,caching=caching, check_extractable=True):\n",
    "        interpreter.process_page(page)\n",
    "\n",
    "    text = retstr.getvalue()\n",
    "\n",
    "    fp.close()\n",
    "    device.close()\n",
    "    retstr.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pg98-99.pdf split.\n"
     ]
    }
   ],
   "source": [
    "#READ THE INPUT DIRECTORY AND SPLIT ALL THE PDF FILES\n",
    "import os\n",
    "from shutil import copyfile\n",
    "read_dir=\"C:/Users/Christopher/Doten/\"\n",
    "\n",
    "for input_filename in os.listdir(read_dir):\n",
    "    path = os.path.join(read_dir, input_filename)\n",
    "    if os.path.isdir(path): continue\n",
    "    pages = input_filename.split(\".\")\n",
    "    pages = pages[0].split(\"pg\")[1]\n",
    "    if \"-\" in pages:\n",
    "        pages = pages.split('-')\n",
    "        out1=read_dir + \"split/\"+pages[0].zfill(5)+\".pdf\"\n",
    "        out2=read_dir + \"split/\"+pages[1].zfill(5)+\".pdf\"\n",
    "        split_pages(read_dir+input_filename,out1,out2)        \n",
    "    else:\n",
    "        out_filename = read_dir+\"split/\"+input_filename.split('pg')[1].split(\".\")[0].zfill(5)+\".pdf\"\n",
    "        copyfile(read_dir+input_filename, out_filename)\n",
    "    print \"\\r\",input_filename + \" split.\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: 00101.txt\n"
     ]
    }
   ],
   "source": [
    "#GRAB AND EXPORT PDF OCR LAYER\n",
    "\n",
    "import os\n",
    "read_dir=\"C:/Users/Christopher/Doten/split/\"\n",
    "for filename in os.listdir(read_dir):\n",
    "    filepath = os.path.join(read_dir, filename)\n",
    "    if os.path.isdir(filepath): continue\n",
    "    output = filename.split('.')[0] + \".txt\"\n",
    "    text = convert_pdf_to_txt(filepath)\n",
    "    with open(read_dir+\"txt/\"+output,\"w\") as out:\n",
    "        out.write(text)\n",
    "    print \"\\r\",\"Output: \" + output,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV outputted\n"
     ]
    }
   ],
   "source": [
    "#PROCESS THE TEXT\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "#read_dir=\"C:/Users/Christopher/Doten/split/txt/\"\n",
    "read_dir=\"I:/Dropbox/NDAD/Doten/split/txt/\"\n",
    "year=\"\"\n",
    "place=\"\"\n",
    "text=\"\"\n",
    "\n",
    "def process_text(line,kwords,days):\n",
    "    line = line.replace(\"(cid:173)\",\"\").rstrip(\"\\n\") + \" \"\n",
    "    for kword in kwords:\n",
    "        tokens = line.split(\" \")\n",
    "        if kword in tokens[0]:\n",
    "            line = '</p><p><div class=\"date\">'\n",
    "            for idx,token in enumerate(tokens):\n",
    "                try:\n",
    "                    int(token)\n",
    "                    if tokens[idx+1] == \"through\": continue\n",
    "                except:\n",
    "                    continue\n",
    "                line+= \" \".join(tokens[0:idx+1]) + \"</div>\" + \" \".join(tokens[idx+1:])\n",
    "                break\n",
    "            break\n",
    "    return line\n",
    "\n",
    "days = [\"Sunday\",\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\"]\n",
    "months = [\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\",\n",
    "         \"Jan\",\"Feb\",\"Mar\",\"Apr\",\"Jun\",\"Jul\",\"Aug\",\"Sept\",\"Oct\",\"Nov\",\"Dec\"]\n",
    "kwords = days+months\n",
    "\n",
    "df = pd.DataFrame(columns=('page', 'place','year', 'text'))\n",
    "\n",
    "for filename in os.listdir(read_dir):\n",
    "    filepath = os.path.join(read_dir, filename)\n",
    "    if filename.endswith('.txt'):\n",
    "        with open(filepath,\"r\") as f:\n",
    "            text=\"<p>\"\n",
    "            page = int(filename.split(\".\")[0])\n",
    "            if int(page%2!=0):\n",
    "                for idx,line, in enumerate(f):\n",
    "                        if idx == 0:\n",
    "                            chunks = line.split(\":\")\n",
    "                            try:\n",
    "                                place=chunks[0].strip()\n",
    "                                year = chunks[1].strip()\n",
    "                            except:\n",
    "                                pass\n",
    "                        elif idx > 3:\n",
    "                            text += process_text(line,kwords,days)  \n",
    "            else:\n",
    "                for idx,line, in enumerate(f):\n",
    "                        if idx > 3:\n",
    "                            text += process_text(line,kwords,days)     \n",
    "        text+=\"</p>\"\n",
    "        result = [str(page),place,year,text]\n",
    "        df.loc[df.shape[0]]=result\n",
    "df.to_csv(read_dir+\"doten-diaries.csv\")\n",
    "print \"CSV outputted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p>some pretty girls, very prettily dressed, with short trousers which became them much, I thought -  frocks and turkish  </p><p><div class=\"date\">July 11</div>... Afternoon I went to see Dr D D Cogswell and had three of my double teeth filled - 10 dollars apiece - A Mr Steward was hung for murder by the people, down at the end of long wharf - He was arrested yesterday -  </p><p><div class=\"date\">July 12 through 26</div>[AD visits, sees the sights, gets three more teeth filled, goes back to Stockton on the Weber, to Chinn\\'s by stagecoach and out to his diggings on foot - Of interest:]  .  </p><p><div class=\"date\">July 14</div>. . Morning I went down on long wharf. There I met Nelson Pierce, who has just arrived from the Sandwich Islands with a load of vegetables - He has got Ellis B Barnes with him as mate. I went on board and Ellis set me into the watermelons and bananas .  .  .  </p><p><div class=\"date\">July 15</div>... Steamer Pacific sailed for Panama - I sent home two letters, and two copies of the Alta California . . Evening I took a walk into town with Seth and saw the sights, heard the music &c and twigged the \"bloomer costumes,\" which are quite plenty now.  .  </p><p><div class=\"date\">Sunday, July 20</div>... I wrote two letters - one to send by Stevens to father - and the other and a box with a fan, specimens &cin it to M-  </p><p><div class=\"date\">July 23</div>... Evening I found Chinn [in Stockton], and we took a turn about town - Went to some of the houses, saw some of the senoritas . .  .  </p><p><div class=\"date\">Sunday, July 27</div>- Clear and very pleasant - I went up to our quartz vein today to see how they get along - There are 6 of the company at work there now - They have sunk two holes, one 40 feet deep and the other about 5 feet deep - They have not struck the quartz ledge yet but there is a very good prospect of finding it soon - In one of the claims next to us there was 6,000 dollars taken out on Friday last and as much more in sight - So we think our prospect is good yet. I got back home about 11 o\\'clock in the evening-  </p><p><div class=\"date\">July 28 through Sept 6</div>[AD makes three more trips to the \"quartz vein,\" which still isn\\'t found, and is visited by his brother-in-law, Seth Morton, who buys into the Hope Quartz Co for 77 dollars. AD works the old diggings a little for minor returns, collects a 30-dollar assessment for the Co, sprains an ankle badly, keeps store briefly for Perry & Quimby - No details of interest.]  \\x0c </p>'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text = df.get_value(90,'text')\n",
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
